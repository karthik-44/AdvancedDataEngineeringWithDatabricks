# Advanced Data Engineering With Databricks  
### Course Description  

This course built upon the knowledge of Apache Spark, Structured Streaming, and Delta Lake to unlock the full potential of the data lakehouse by utilizing the suite of tools provided by Databricks. This course places a heavy emphasis on designs favoring incremental data processing, enabling systems optimized to continuously ingest and analyze ever-growing data. By designing workloads that leverage built-in platform optimizations, data engineers can reduce the burden of code maintenance and on-call emergencies, and quickly adapt production code to new demands with minimal refactoring or downtime.   

### Learning Outcomes

- Designed databases, pipelines and optimized for the Databricks Lakehouse Platform.
- Implemented efficient incremental data processing to validate and enrich data driving business decisions and applications.
- Leveraged Databricks-native features for managing access to sensitive data and fulfilling right-to-be-forgotten requests.
- Managed code promotion, task orchestration, and production job monitoring using Databricks tools.


### Prerequisites

- Experience using PySpark APIs to perform advanced data transformations.
- Familiarity implementing classes with Python.
- Experience using SQL in production data warehouse or data lake implementations.
- Experience working in Databricks notebooks and configuring clusters.
- Familiarity with creating and manipulating data in Delta Lake tables with SQL.
- Ability to use Spark Structured Streaming to incrementally read from a Delta table.
